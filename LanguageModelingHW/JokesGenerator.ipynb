{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1c368f2",
   "metadata": {},
   "source": [
    "#### Генератор прикольчиков и раздаватель смешков\n",
    "Базовый [датасет](https://disk.yandex.com/d/fjt5xICH-ukEEA)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b35b1cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0ed11c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from dataset import TextDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Пользуемся библиотекой [sentencepiece](https://github.com/google/sentencepiece) для создания датасета"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[2, 3],\n        [4, 5]])"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([[1,2], [3,4]]) + 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 256\n",
    "VOCAB_SIZE = 6000\n",
    "RNN_LAYERS = 3\n",
    "DROPOUT = 0.4"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "train_set = TextDataset(data_file='mega_jokes_dataset.txt', train=True, sp_model_prefix='bpe', vocab_size=VOCAB_SIZE)\n",
    "valid_set = TextDataset(data_file='mega_jokes_dataset.txt', train=False, sp_model_prefix='bpe', vocab_size=VOCAB_SIZE)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# тесты\n",
    "for _ in range(5):\n",
    "    for dataset in (train_set, valid_set):\n",
    "        indices, length = dataset[np.random.randint(len(dataset))]\n",
    "        assert indices.shape == (dataset.max_length, )\n",
    "        assert indices[0].item() == dataset.bos_id\n",
    "\n",
    "        eos_pos = indices.tolist().index(dataset.eos_id)\n",
    "        assert torch.all(indices[eos_pos + 1:] == dataset.pad_id)\n",
    "        assert (indices != dataset.pad_id).sum() == length"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Бахнем модель"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "from model import LanguageModel"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99427388",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LanguageModel(train_set, embed_size=EMBEDDING_DIM, hidden_size=EMBEDDING_DIM, rnn_layers=RNN_LAYERS, dropout=DROPOUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "199406f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# тесты\n",
    "for bs in [1, 4, 16, 64, 256]:\n",
    "    indices = torch.randint(high=train_set.vocab_size, size=(bs, train_set.max_length))\n",
    "    lengths = torch.randint(low=1, high=train_set.max_length + 1, size=(bs, ))\n",
    "    logits = model(indices, lengths)\n",
    "    assert logits.shape == (bs, lengths.max(), train_set.vocab_size)\n",
    "\n",
    "for prefix in ['', 'купил мужик шляпу,', 'сел медведь в машину и', 'подумал штирлиц']:\n",
    "    generated = model.inference(prefix, temp=np.random.uniform(0.1, 10))\n",
    "    assert type(generated) == str\n",
    "    assert generated.startswith(prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7eacf83",
   "metadata": {},
   "source": [
    "Обучим блин"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "PS: Торч считает лосс по последнему измерению, как бы ни были упакованы тензоры. Например, для кросс-энтропии, последней размерности, содержащий вектор, тензора a будет сопоставлена последняя размерность тензора b, содержащая числа, а для MAE (ниже) сопоставление будет 1 к 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(1.2500)"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "crit = nn.L1Loss()\n",
    "a = torch.tensor([[1., 1.],\n",
    "                  [1.5, 1.5]])\n",
    "b = torch.tensor([[2., 2.],\n",
    "                  [3., 3.]])\n",
    "\n",
    "crit(a, b)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Выкладка здесь касается MAE лосса\n",
    "Для кросс-энтропии число классов должно идти сразу посл батча (N x C x d1 x ... x dn)\n",
    "Правильные ответы (N x d1 x ... x dn)\n",
    "В нашем случае веротяности сначала разложены по классам, а только потом по словам в тексте.\n",
    "pi - вероятность, что дальше идет слово i\n",
    "Получим такую матрицу для одного текста в батче:\n",
    "p1(x1) ... p1(xl)\n",
    "p2(x1) ... p2(xl)\n",
    "...\n",
    "pN(x1) ... pN(xl)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(0.8544, dtype=torch.float64)"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = torch.tensor([ # vocab_size = 3 words\n",
    "    [\n",
    "        [0.5, 0.4, 0.1], # text1\n",
    "        [0.6, 0.2, 0.2]\n",
    "    ],\n",
    "    [\n",
    "        [0.3, 0.6, 0.1], # text2\n",
    "        [0.1, 0.2, 0.7]\n",
    "    ]\n",
    "], dtype=torch.float64)\n",
    "logits = torch.transpose(logits, 1, 2)\n",
    "\n",
    "targets = torch.tensor([\n",
    "    [0, 0], # text1\n",
    "    [1, 2] # text2\n",
    "], dtype=torch.int64)\n",
    "crit = nn.CrossEntropyLoss()\n",
    "crit(logits, targets)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation examples:\n",
      "1. говорит мать людям весей. после чего уже учапели «сею, может это гаика? —поллекп? - нет, видно, здесь нет. у нас нет.\n",
      "2. в юбку мужику и говорит: - девушка, купи мне спрабые кристи за добром\n",
      "3. ская женщина делите -я у мепыле и олом до своих базараю наковалались пропасть \"скократисты купить успех в полицию...- страшная?- да понюшал первымносата дорожном гестом. ну, что ты косяете?- оказывается, что ты такой юж: — вопрос машья? — а че, у нас смогу барабан? - или же тебе определить? она позавчера: идут недопрохиво, ничего и думал, что резятником. на голове и вдруг спрашивает мужу: в дом.\n",
      "4. нас умерра?- как ты об этом начинаем?\n",
      "5. девушки, где замечается ему что произошло? удивился как мы.\n"
     ]
    }
   ],
   "source": [
    "import train\n",
    "\n",
    "BATCH_SIZE = 256\n",
    "NUM_EPOCHS = 7\n",
    "MODEL_NAME = \"baseline2\"\n",
    "MODEL_PATH = MODEL_NAME + \"_checkpoint\" + \".pt\"\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.93)\n",
    "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(valid_set, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "if not os.path.isfile(MODEL_PATH):\n",
    "    train.train(model, optimizer, scheduler, train_loader, val_loader, NUM_EPOCHS, saving_path=MODEL_PATH)\n",
    "else:\n",
    "    state_dict = torch.load(MODEL_PATH)\n",
    "    model.load_state_dict(state_dict[\"model_state_dict\"])\n",
    "    train.generate_examples(model)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([0.0339, 0.2507, 0.6815, 0.0339], dtype=torch.float64)"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([1,2,3,4], dtype=torch.float64)\n",
    "a[[0, 3]] = 0\n",
    "torch.softmax(a, dim=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "А теперь LSTM"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d457cd6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation examples:\n",
      "1. ребёнка шлаку и мордному сезтальтор дрюйца бупает в туффуку. съел секретаршил нафиг, третий день все равносплюлиста. иположенная люди в окоси один стоящий, только во всем его начинают ножаться выбраться, вдруг стоит в магазине каннялись, а написать раздается собесекан. но видит на третий 3 жизни саженчики объясняет вылезает класс. стал стыдника, ему полилой учления! ну утром теперь лешка, сейчас расставил коробку, и наблюскается и казь и спросил минуту поверляет,.\n",
      "2. , умер, оглядьться. одна не знает, как асфальт,ва, она возмуспеваливают, наэй тишина, выпивается от глаза и говорят: - \"не белов, негр польмер развратки и димёп и всё время?? ничё) подписаться в встресло купрое вопркой. состарился втроющий правоводелся. так, следущегое предпанным и чисту: - обиверной тебя (премнего увидел же сигарет. тот ловит курица унесенький и говорит: - привет, двач, как хуй наш заяц. второй: -\n",
      "3. путарь притдортовов. выступает, на квадратных слабоктовы сидит поибориенными фазенгистью. окуганли подходит клад деда после женщин. одна другому спрашивает: \"припевший такой перенюктор: \"это есть книга члена начинается стать лошадь, оторвай». в выезжает к вам два попушемлет: — полново, глядя.. рыбка говорит: — из стадный дело чистай достает знаете узыстоны — разднули паросты и плохо\n",
      "4. сканила длинное операардает инструстеры и открывает замовку и говорит ему\n",
      "5. одной школе клудания две обдает. заходят главный пожарн: — для чего это сын? — . . . . . . . второй мы принять его: — бармен дожаньте. — dужш две скеальную пальцем! — ну??? командип: — ну может что ему соще? — со стыде бол» \"нет\". — принята, брат, я старь\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 256\n",
    "NUM_EPOCHS = 7\n",
    "RNN_LAYERS = 2\n",
    "MODEL_NAME = \"lstm\"\n",
    "MODEL_PATH = MODEL_NAME + \"_checkpoint\" + \".pt\"\n",
    "\n",
    "\n",
    "model = LanguageModel(train_set, embed_size=EMBEDDING_DIM, hidden_size=EMBEDDING_DIM, rnn_layers=RNN_LAYERS, dropout=DROPOUT, rnn_type=torch.nn.LSTM)\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.93)\n",
    "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(valid_set, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "if not os.path.isfile(MODEL_PATH):\n",
    "    train.train(model, optimizer, scheduler, train_loader, val_loader, NUM_EPOCHS, saving_path=MODEL_PATH)\n",
    "else:\n",
    "    state_dict = torch.load(MODEL_PATH)\n",
    "    model.load_state_dict(state_dict[\"model_state_dict\"])\n",
    "    train.generate_examples(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
