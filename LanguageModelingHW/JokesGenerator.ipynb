{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1c368f2",
   "metadata": {},
   "source": [
    "## Генератор прикольчиков и раздаватель смешков"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Постановка задачи:\n",
    "Обучим генеративную модель для генерации анекдотов\n",
    "\n",
    "##### Сбор данных:\n",
    "1. Скачаем базовый [датасет](https://disk.yandex.com/d/fjt5xICH-ukEEA) из открытых источников\n",
    "2. Напишем парсер телеграмм каналов (telegram_parser.py), соберем еще анекдотов\n",
    "3. Обработаем собранные анекдоты и расширим ими датасет\n",
    "\n",
    "##### Построение модели:\n",
    "1. Токенизируем тексты (пробуем sentencepiece bpe tokenizer с разным размером словаря)\n",
    "2. Используем RNN и LSTM бейзлайн, обучая эмбеддинги вместе с моделью\n",
    "3. С нуля обучаем декодер из Transformer (не сделано, но начало положено в папке Transformer. Там я хотел сначала протестировать его на классификации текстов)\n",
    "4. Дообучаем BERT, GPT (не сделано)\n",
    "\n",
    "##### Создание интерфейса:\n",
    "1. Используем Gradio\n",
    "2. Переезжаем на FastApi бэкенд (не сделано)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0ed11c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from dataset import TextDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Пользуемся библиотекой [sentencepiece](https://github.com/google/sentencepiece) для создания датасета"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 256\n",
    "VOCAB_SIZE = 6000\n",
    "RNN_LAYERS = 3\n",
    "DROPOUT = 0.4"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "train_set = TextDataset(data_file='mega_jokes_dataset.txt', train=True, sp_model_prefix='bpe', vocab_size=VOCAB_SIZE)\n",
    "valid_set = TextDataset(data_file='mega_jokes_dataset.txt', train=False, sp_model_prefix='bpe', vocab_size=VOCAB_SIZE)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# тесты\n",
    "for _ in range(5):\n",
    "    for dataset in (train_set, valid_set):\n",
    "        indices, length = dataset[np.random.randint(len(dataset))]\n",
    "        assert indices.shape == (dataset.max_length, )\n",
    "        assert indices[0].item() == dataset.bos_id\n",
    "\n",
    "        eos_pos = indices.tolist().index(dataset.eos_id)\n",
    "        assert torch.all(indices[eos_pos + 1:] == dataset.pad_id)\n",
    "        assert (indices != dataset.pad_id).sum() == length"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Обучение бейзлайна\n",
    "Архитектура: несколько слоев RNN / LSTM подряд\n",
    "\n",
    "Гиперпараметры токенизатора:\n",
    "    - Тип токенизации\n",
    "    - Размер словаря\n",
    "\n",
    "Гиперпараметры модели:\n",
    "    - Размерность эмбеддингов\n",
    "    - RNN / LSTM\n",
    "    - Число слоев\n",
    "    - Dropout между слоями\n",
    "\n",
    "Гиперпараметры обучения:\n",
    "    - Оптимизатор\n",
    "    - Размер батча\n",
    "    - Число эпох"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "from model import LanguageModel"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "model = LanguageModel(train_set, embed_size=EMBEDDING_DIM, hidden_size=EMBEDDING_DIM, rnn_layers=RNN_LAYERS, dropout=DROPOUT)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# тесты\n",
    "for bs in [1, 4, 16, 64, 256]:\n",
    "    indices = torch.randint(high=train_set.vocab_size, size=(bs, train_set.max_length))\n",
    "    lengths = torch.randint(low=1, high=train_set.max_length + 1, size=(bs, ))\n",
    "    logits = model(indices, lengths)\n",
    "    assert logits.shape == (bs, lengths.max(), train_set.vocab_size)\n",
    "\n",
    "for prefix in ['', 'купил мужик шляпу,', 'сел медведь в машину и', 'подумал штирлиц']:\n",
    "    generated = model.inference(prefix, temp=np.random.uniform(0.1, 10))\n",
    "    assert type(generated) == str\n",
    "    assert generated.startswith(prefix)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation examples:\n",
      "1. говорит мать людям весей. после чего уже учапели «сею, может это гаика? —поллекп? - нет, видно, здесь нет. у нас нет.\n",
      "2. в юбку мужику и говорит: - девушка, купи мне спрабые кристи за добром\n",
      "3. ская женщина делите -я у мепыле и олом до своих базараю наковалались пропасть \"скократисты купить успех в полицию...- страшная?- да понюшал первымносата дорожном гестом. ну, что ты косяете?- оказывается, что ты такой юж: — вопрос машья? — а че, у нас смогу барабан? - или же тебе определить? она позавчера: идут недопрохиво, ничего и думал, что резятником. на голове и вдруг спрашивает мужу: в дом.\n",
      "4. нас умерра?- как ты об этом начинаем?\n",
      "5. девушки, где замечается ему что произошло? удивился как мы.\n"
     ]
    }
   ],
   "source": [
    "import train\n",
    "\n",
    "BATCH_SIZE = 256\n",
    "NUM_EPOCHS = 7\n",
    "MODEL_NAME = \"baseline2\"\n",
    "MODEL_PATH = MODEL_NAME + \"_checkpoint\" + \".pt\"\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.93)\n",
    "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(valid_set, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "if not os.path.isfile(MODEL_PATH):\n",
    "    train.train(model, optimizer, scheduler, train_loader, val_loader, NUM_EPOCHS, saving_path=MODEL_PATH)\n",
    "else:\n",
    "    state_dict = torch.load(MODEL_PATH)\n",
    "    model.load_state_dict(state_dict[\"model_state_dict\"])\n",
    "    train.generate_examples(model)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "А теперь LSTM"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d457cd6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation examples:\n",
      "1. ребёнка шлаку и мордному сезтальтор дрюйца бупает в туффуку. съел секретаршил нафиг, третий день все равносплюлиста. иположенная люди в окоси один стоящий, только во всем его начинают ножаться выбраться, вдруг стоит в магазине каннялись, а написать раздается собесекан. но видит на третий 3 жизни саженчики объясняет вылезает класс. стал стыдника, ему полилой учления! ну утром теперь лешка, сейчас расставил коробку, и наблюскается и казь и спросил минуту поверляет,.\n",
      "2. , умер, оглядьться. одна не знает, как асфальт,ва, она возмуспеваливают, наэй тишина, выпивается от глаза и говорят: - \"не белов, негр польмер развратки и димёп и всё время?? ничё) подписаться в встресло купрое вопркой. состарился втроющий правоводелся. так, следущегое предпанным и чисту: - обиверной тебя (премнего увидел же сигарет. тот ловит курица унесенький и говорит: - привет, двач, как хуй наш заяц. второй: -\n",
      "3. путарь притдортовов. выступает, на квадратных слабоктовы сидит поибориенными фазенгистью. окуганли подходит клад деда после женщин. одна другому спрашивает: \"припевший такой перенюктор: \"это есть книга члена начинается стать лошадь, оторвай». в выезжает к вам два попушемлет: — полново, глядя.. рыбка говорит: — из стадный дело чистай достает знаете узыстоны — разднули паросты и плохо\n",
      "4. сканила длинное операардает инструстеры и открывает замовку и говорит ему\n",
      "5. одной школе клудания две обдает. заходят главный пожарн: — для чего это сын? — . . . . . . . второй мы принять его: — бармен дожаньте. — dужш две скеальную пальцем! — ну??? командип: — ну может что ему соще? — со стыде бол» \"нет\". — принята, брат, я старь\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 256\n",
    "NUM_EPOCHS = 7\n",
    "RNN_LAYERS = 2\n",
    "MODEL_NAME = \"lstm\"\n",
    "MODEL_PATH = MODEL_NAME + \"_checkpoint\" + \".pt\"\n",
    "\n",
    "\n",
    "model = LanguageModel(train_set, embed_size=EMBEDDING_DIM, hidden_size=EMBEDDING_DIM, rnn_layers=RNN_LAYERS, dropout=DROPOUT, rnn_type=torch.nn.LSTM)\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.93)\n",
    "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(valid_set, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "if not os.path.isfile(MODEL_PATH):\n",
    "    train.train(model, optimizer, scheduler, train_loader, val_loader, NUM_EPOCHS, saving_path=MODEL_PATH)\n",
    "else:\n",
    "    state_dict = torch.load(MODEL_PATH)\n",
    "    model.load_state_dict(state_dict[\"model_state_dict\"])\n",
    "    train.generate_examples(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Предварительные выводы:\n",
    "у бейзлайна сносит крышу, если честно.\n",
    "Анекдоты, конечно, получились смешные, но далеко не потому что я построил хорошую модель...\n",
    "У сгенерированных примеров видим слабую языковую структуру и очень много несуществующих слов, однако что-то модель все же выучила, и, читая примеры, мы можем даже догадаться, что это должны быть анекдоты)\n",
    "\n",
    "\n",
    "#### Идеи по улучшению:\n",
    "1. Я допустил багу, ее нао найти и пофиксить)\n",
    "2. Происходят взрывы градиентов, стоит попробовать клиппинг в цикле обучения\n",
    "3. Выучить эмбеддинги отдельно от модели (Например, использовать word2vec из Embeddings.ipynb)\n",
    "4. У модели около 4М параметров, так что возможно набор данных для нее очень мал, нужно использовать fine-tuning, чтобы сначала выучить языковую структуру"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
